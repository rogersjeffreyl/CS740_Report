\section{Methodology}
THe first step in our study was to gain insight into the working of AdBlock Plus and the different filters it uses.
~\cite{walls2015measuring} explain in detail about filter specification and the functionality of different kinds of filters.
Additionally, we used a tool called the Element Hiding helper ~\cite{elemhidehelper}  to identify the correspondence between the filter and the actual web page elements displayed.
Element Hiding Filter Helper a Firefox add-on that aids in analyzing the ads that were blocked.
It identifies and highlights an element blocked by AdBlock Plus, provides the content type of the element and the maching URL or element hiding filter that caused the element to be blocked.

We then proceeded to examine and measure the impact of AdBlock Plus, through four different experiments:
\begin{enumerate}
	\item[(a)] Growth of whitelist over the years and its impact on adblocking
	\item[(b)] The impact of whitelists on AdBlock Plus's blocking mechanisms
    \item[(c)]If we do away with the notion of lists, can we see how AdBlock Plus performs with respect to only the element hiding filters.
    \item[(d)] Fuzzing the page to prevent AdBlock Plus from recognizing the ads in the page.

\end{enumerate}

\subsection{Crawling}
For our experiments we needed to examine a corpus of webpages with advertisements.
Crawling of webpages is the standard way of obtaining the content of the webpages.
However normal crawling of webpages would just fetch the source of the page offline and there by mask the additional communication made between the  advertisement and the adserver.
This might result in elements  missing from the page source which would have otherwise been present if the page were online.
This calls for a crawling mechanism which mimics the behavior of an actual browser.
The crawler should also provide us with the capability of analyzing the DOM(Document Object Model) of the page.

AdBlock Plus has developed a tool called abpcrawler ~\cite{abpcrawler} that launches a webpage in realtime.
This tool takes in as input a list of urls to crawl. The tool launches the URLs in the browser and logs the filters,both blacklist and whitelist that had matches in the pages.

This tool uses the Gecko layout engine of Firefox to launch the browser with a pre-specified url. This tool also
provides the  source of a webpage in xml and also returns the visual representation of the webpage as an image.
Additionally the tool also logs the  AdBlock Plus filters applied to the page as a json file. This allows us analyze the type of filters fired for a given webpage. Following is an  entry in the json file:
\begin{lstlisting}
 {
  "contentType": "SCRIPT",
  "filter": null,
  "location": "http://platform.twitter.com/widgets.js"
  }
\end{lstlisting}
\subsection{Variations In Filter Lists}
We also needed capabilities to specify the filter lists used by AdBlock Plus when it examines a webpage.
AdBlock Plus provides two means of configuring the whitelist and blacklists through it's GUI. Users  could add subscription to the filters they wanted by specifying an  URL to the filter-file.
Additionally, an option is provided to the users for configuring AdBlock Plus to use the whitelist, i.e acceptable ads. This option is enabled by default.

The abp crawler, however, did not have means through which filter lists could be configured.
We created Firefox profiles for this purpose, one for a particular combination of filter lists used in our experiments. For each of the profiles we installed AdBlock Plus and configured it with a particular combination of filter lists.
The abpcrawler was enhanced to use the profile information.
This enhanced abpcrawler working is outlined in the following steps:
\begin{algorithm}
\caption{Crawler}\label{euclid}
\begin{algorithmic}[1]
\Procedure{Crawl Web pages}{}
\State $\textit{configurations} \gets \text{Variations In Filter Lists}$
\State $\textit{urls} \gets \text{urls to crawl}$
\ForAll{urls}
\ForAll{configurations}
\State \text{Launch firefox with configuration}
\State \text{In JSON format, write to a file the following}
\State \textit{Content type of the element}
\State \textit{Filter regex(null if no filter is applied)}
\State \textit{Location of the element within the page.}
\EndFor
\EndFor
\Return
\EndProcedure
\end{algorithmic}
\end{algorithm}

Thus for our experiments, the configuration in step 2 alone needs to be changed. For example, to see the impact of the change in whitelist, the URL corresponding to the version of whitelist is configured, and the crawler is run.

\subsection{Growth of Whitelist}
We wanted to measure the impact of the growth of whitelist over time. For this we used different versions of whitelists and blacklists  from  2012 to 2016. We leveraged the capability of our modified crawled to  use the different versions of whitelist and blacklists. For a given list of URLS filters corresponding to the years were applied and the number of filter matches per webpage was measured.

\subsection{Measuring performance of Adblock Plus}:
An important aspect in asnwering ~\ref{q:q1} and ~\ref{q:q4} is to see the impact of URL filters on AdBlock Plus's performance. For this purpose we  create a new version of the blacklist , containing only element hiding filters.We then measure the number of elements blocked by AdBlock Plus with three configurations of filters: the normal AdBlock Plus with default blacklist and whitelist, only the default blacklist and the new blacklist with the  element hiding filters.

A very simple measurement of the number of ads blocked is to count the number of non-null and blocking filters from the JSON file.
However, this does not give us a correct measure of the numer of advertisements blocked.
We observed a higher number of elements blocked with a combination of both blacklist and whitelist filters when compared to a configuration of only blacklist.
The count of blocking filters fired is greater for AdBlock Plus with default blacklist and whitelist because  of the fact that whitelist allows more ads to pass through. This causes additional blocking filters to be fired.
Whereas in the case of blacklists since the number of ads  allowed is lesser that that of the  one with the whitelist there are lesser opportunities for the blocking filters to trigger.
The actual number of elements blocked , thus has to be calculated  with reference to the number of elements in the page which would have been displayed  if there were no Adblock plus in the browser.

We come up with a simple formula that would give us the number of elements blocked:

let N be the actual number of elements  in the page, without any blocking. \\
let B be the number of elements blocked per page.\\
Let C be the  number of elements currently present in the page after applying adblocking. \\
\begin{equation}
Effectively Blocked Elements (EB) = N - C
\end{equation}
\begin{equation}
 Total Blocked Elements (TB) = EB + C
\end{equation}
\subsection{Fuzzing}
AdBlock Plus blocks elements by hiding the elements that match the filters. This means that the blocking mechanism can be considered as a string matching process.Thus, circumventing the string matching process would then allow the ad to be displayed. We used the following methods for overriding the filters in the webpage:
\begin{enumerate}
  \item  Rewriting the ids of the elements with a random id.
  \item  Rewriting the URLS present in the page  with a shortened URL from bit.ly.
\end{enumerate}
 The webpages were then launched in a browser with Adblock Plus enabled.









